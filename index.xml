<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Graham Tierney on Graham Tierney</title>
    <link>/</link>
    <description>Recent content in Graham Tierney on Graham Tierney</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 -0500</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Article Round Up June 2018: Income Inequality, Partisan Economies, and Trump Tweets to Hate Crimes</title>
      <link>/post/2018_06_best_reads/</link>
      <pubDate>Thu, 07 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018_06_best_reads/</guid>
      <description>&lt;p&gt;This is my second article round up. The first is over at &lt;a href=&#34;https://ticktocksaythehandsoftheclock.wordpress.com/2018/04/06/march-2018-universities-fake-news-and-drugs/&#34;&gt;my old blog here&lt;/a&gt;. In this post, I’ll briefly cover two Atlantic articles related to economic inequality and the differing economic expectations of democrats and republicans. Most time is spent reviewing a new working paper on the correlation between Trump’s twitter activity and hate crimes, and thinking about how it could make the jump from correlation to causation.&lt;/p&gt;
&lt;div id=&#34;income-inequality&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Income Inequality&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Matthew Stuart’s &lt;a href=&#34;https://www.theatlantic.com/magazine/archive/2018/06/the-birth-of-a-new-american-aristocracy/559130/&#34;&gt;“The 9.9 Percent Is the New American Aristocracy”&lt;/a&gt; and Jordan Weissman’s reply &lt;a href=&#34;https://slate.com/business/2018/05/forget-the-atlantics-9-9-percent-the-1-percent-are-still-the-problem.html&#34;&gt;“Actually, the 1 Percent Are Still the Problem”&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The first article is quite long, but easily skim-able. It focuses on not the super wealthy but the elite professionals that make up the upper class and the pernicious ways that group has convinced itself that membership is meritocratic when in reality parental wealth is inherited to a high degree. The various mechanism for this inheritance are in the article (knowing what preschools to go to, what SAT tutors to hire, etc.), but it also pointed out that this group (to which I belong) often refuses to acknowledge that they are upper class and do not represent the “average American.” And that self-delusion of meritocracy can be quite dangerous when it is used to justify the status quo.&lt;/p&gt;
&lt;p&gt;Weissman’s response makes the valid point that the top 90th percentile to the 99.9th percentile of the income distribution are quite heterogeneous: the elite professionals are in there but also are old retirees. And he points out that the difference in wealth and privilege between the 90th and 99th percentiles is quite large. Therefore, the 9.9% are not even a cohesive group, let alone “the New American Aristocracy.” Often when reading about a subject I’m not personally knowledgeable on, I find myself agreeing with whoever I’m reading. This Slate article pushed back on the data and factual claims in a way that I wouldn’t have been able to do myself just assessing the analytical arguments.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;partisan-economies&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Partisan Economies&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Annie Lowrey’s &lt;a href=&#34;https://www.theatlantic.com/politics/archive/2018/06/two-economies/561929/&#34;&gt;“Left Economy, Right Economy”&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;An interesting look into how the partisan change in post-election economic expectations hasn’t disappeared after 2016. The article goes into how democrats and republicans have radically different economic expectations. This is one of the more easily measured areas of where partisan beliefs can impact non-political opinions. They also cite some good research that “politically-motivated” beliefs about the direction of the economy don’t impact consumer spending, indicating that perhaps the people espousing the motivated beliefs know that they are untrue.&lt;/p&gt;
&lt;p&gt;On some level, this shouldn’t be surprising. Democrats and republicans disagree on the empirical question of which policies improve the economy. On the other hand, to the extent that economies aren’t that impacted by government policies, it is a huge collection of people looking at the same data and coming to opposite conclusions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;trump-tweets-and-hate-crimes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Trump Tweets and Hate Crimes&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Karsten Müller and Carlo Schwarz’s &lt;a href=&#34;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3149103&#34;&gt;“Making America Hate Again? Twitter and Hate Crime Under Trump”&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A lot has been written about whether the 2016 election and Trump’s campaign emboldened racists. A new working paper from economists at the University of Warwick took a look at whether Trumps activity on Twitter is related to an increase in hate crimes. The abstract is below.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;: Social media has come under increasing scrutiny for reinforcing people’s pre-existing viewpoints which, it is argued, can create information “echo chambers.” We investigate whether social media motivates real-life action, with a focus on hate crimes in the United States. We show that the rise in anti-Muslim hate crimes since Donald Trump’s presidential campaign has been concentrated in counties with high Twitter usage. Consistent with a role for social media, Trump’s Tweets on Islam-related topics are highly correlated with anti-Muslim hate crime after, but not before the start of his presidential campaign, and are uncorrelated with other types of hate crimes. These patterns stand out in historical comparison: counties with many Twitter users today did not consistently experience more anti-Muslim hate crimes during previous presidencies.&lt;/p&gt;
&lt;/blockquote&gt;
This is the main figure:
&lt;center&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/img/tweets_hate_crimes.png&#34; /&gt;

&lt;/div&gt;
Figure 2: Panel (a) shows the weekly number of Donald Trump’s &lt;br/&gt; Islam-related tweets and the number of anti-Muslim hate crimes &lt;br/&gt; in the US after the start of Trump’s presidential campaign.
&lt;/center&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Some other key results:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;“Trump’s Muslim tweets alone predict more than 20% of the variation in anti-Muslim hate crimes in the same week, but only after his campaign start; the explanatory power is less than 1% before.”&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;“[T]he number of hate crimes [in counties with low and high twitter usage] was more or less constant since 2009. With the start of Donald Trump’s presidential campaign on June, 16th 2015, however, we observe a disproportional increase in the number of hate crimes in those counties where many people use Twitter. There is no comparable increase in counties with low twitter usage.”&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;“In additional exercises, reported in Supplementary Material 6, we find complementary results for Hispanics. While the association weakens somewhat in the immediate run-up to the election in mid-2016, Table A.10 and Table A.11 show that Trump’s tweets about Hispanics have considerable predictive power for Ethnicity-based hate crimes. Again, this only holds true for the period after his campaign start, and not for other types of crime biases.”&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The correlation is quite striking. It kind of makes me wish that the &lt;a href=&#34;https://www.npr.org/sections/thetwo-way/2017/11/03/561770603/twitter-employee-blamed-for-deleting-presidents-account&#34;&gt;Twitter employee who deleted Trump’s account on their last day&lt;/a&gt; would come back to quit every day (or at least pick random days to delete the account).&lt;/p&gt;
&lt;p&gt;I thought this paper was really interesting for a couple of reasons. Foremost, it gets about as close as possible to claiming and showing that a correlation is causal. They do many, many robustness checks that, while imperfect, all indicate that alternative explanations are unlikely. Of course, correlation does not imply causation in the mathematical sense, but it does imply it in the colloquial sense. If Trump’s anti-Muslim tweets are in response to world events that would cause an increase in hate crimes absent his tweets, you would expect a similar correlation between his tweets and hate crimes before his presidential run. But that correlation isn’t observed. If high twitter usage counties are more prone to hate crimes, you would expect elevated levels of hate crimes before he became president. But that correlation also isn’t observed. Other counter arguments to the (unstated) causal claim are similarly addressed.&lt;/p&gt;
&lt;p&gt;If the paper did try to make a causal claim (which it does not), the appropriate counter-factual is an interesting discussion. The counter-factual of anti-Muslim hate crimes under a Clinton presidency is the most relevant for a judgement on Trump’s presidency, but hard to estimate. The counter-factual of Trump wants to send an anti-Muslim tweet but does not or cannot for some reason is less relevant, but much easier to estimate. Some ways to get at this counter-factual would be to identify times when Trump was not able to tweet. I’m not sure if he gets service on Air Force One, but time spent traveling or in meetings could be used as an instrument for his Islam-related tweets. Unfortunately, the time periods he is otherwise occupied with presidential work are probably too short and infrequent. Long periods while he is overseas, he might tweet at odd hours, so the exposure of Twitter to his tweets could be plausibly thought of as exogenously lowered. Essentially these methods try to find “random” reasons that Twitter was more or less less exposed to Trump, then use the variation in Trump’s Islam-related tweets attributable to those random shocks to explain variation in hate crimes. That final explanation is causal because the ultimate source of the variation is random.&lt;/p&gt;
&lt;p&gt;Another way to get at the counter-factual is to try to identify “random” tweets, i.e. anti-Muslim tweets not caused by other events. This kind of analysis has been explored in finance when doing event studies of how unexpected news affects a company’s stock price. Reviews of each of his at-issue tweets and a selection of events that could cause an increase in anti-Muslim hate crimes could identify events and tweets that are linked (such as the travel ban and resulting tweets), events that were not tweeted, and tweets not associated with events. The &lt;a href=&#34;https://www.predictit.org/home/browse?Search=tweets&amp;amp;isSearch=true&#34;&gt;PredictIt markets for the number of tweets he sends each week&lt;/a&gt; could even be used to create “expected” levels of Twitter activity, then deviations from that expectation could be treated as unexpected shocks. Of course, that relies on the strong assumption that PredictIt Twitter markets are efficient. Choosing the events to analyze would be hard too, but you could potentially algorithmically identify events that sparked many tweets related to Islam in the US and select from those.&lt;/p&gt;
&lt;p&gt;This last method gets at what I think is probably the true causal structure. Trump’s election and campaign emboldened people who harbored racial resentment and increased the baseline rate of hate crimes. Trump’s tweets are caused by news-worthy events that would have received coverage on traditional and social media. Those events and the coverage would have caused an increase in hate crimes regardless of his tweets. When he does choose to tweet about them, he increases their exposure and amplifies their impact on anti-Muslim hate crimes. Separating events and tweets into three categories (event-tweet pairs, unpaired events, and unpaired tweets) and comparing before and after Trump’s campaign began can fully test at least the correlations implied by this theory. To the degree that the pairing and non-pairing of tweets and events is exogenous, the correlations become causal as well. That exogeneity isn’t something that can be statistically tested but can come from a qualitative analysis of the time surrounding the event and/or tweet.&lt;/p&gt;
&lt;p&gt;The paper is going through the peer review process, so what comes out the other side may be quite different. It does a lot of interesting analysis and adds to an important discussion about the consequences of the 2016 election. I certainly do not expect this to be the last paper on the impact of Trump on racial resentment in America.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The Genetics of Magic</title>
      <link>/post/magic_classification/</link>
      <pubDate>Thu, 17 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/magic_classification/</guid>
      <description>&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Last spring, I took a class on Bayesian statistics at the University of Chicago that had several exercises focused on building a model to classify species based on their genome. The basic setup was that you were given a data set of salmon, their genome sequencing data, and which sub-population they belonged to. From this data, we needed to build a model to classify new salmon into the sub-populations. The strategy was to use the fact that alleles appeared with different frequencies in the different sub-populations, so the fact that a new fish did have certain alleles and did not have others was informative about which sub-population it came from.&lt;/p&gt;
&lt;p&gt;This problem and solution struck me as being very similar to an issue near and dear to my heart: classifying decks into archetypes in collectible card games (CCGs). Specifically, Magic the Gathering. One could think of alleles as analogues for cards and the sub-populations as analogues for deck archetypes (UW Control, Jund, Merfolk, etc.). In this post, I will describe how to apply a Bayesian classification algorithm to this scenario and discuss some of its advantages. I assume the reader has familiarity with basic mathematical probability and statistics. I also will not show proofs for the mathematical claims that I make, but I will try to explain the intuition behind the concepts. Knowing the application area, collectible card games and Magic, will be necessary to understand the examples.&lt;/p&gt;
&lt;p&gt;Ultimately, with very minimal data cleaning, I am able to correctly classify 80% of decks played in a testing sample. Frequently played archetypes and archetypes that share few cards with others are more accurately classified. The code and data are available on &lt;a href=&#34;https://github.com/g-tierney/magic_deck_classification_multi_dir&#34;&gt;Github&lt;/a&gt;. I also describe some simple human-implementable improvements and additional features that should be included in practice.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-problem&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Problem&lt;/h2&gt;
&lt;p&gt;Magic, and collectible card games broadly, are usually two-player games where each player brings their own deck of different cards. Many tournament-caliber decks are categorized into broader archetypes that differ only slightly. For example, Merfolk is a deck that plays creature cards with the Merfolk creature type and “lords” that give bonuses to all Merfolk cards. Not all Merfolk decks are identical, but a human who knows the game well can easily look at a deck-list and say if it is a Merfolk deck or not. Jund is a deck that plays green, black, and red cards that focus on trading resources with the opponent while eking out small advantages in each exchange. The variety of cards played in Jund is significantly higher than the variety of cards played in Merfolk decks.&lt;/p&gt;
&lt;p&gt;Classifying a single deck into an archetype is an easy task for a human who knows the game well, but frequently this classification has to be done at scale. Large tournaments happen every weekend, thousands of matches are played online every day, and it would take an extremely large team to classify all of those decks. A classification algorithm would ideally give a data-driven, suggested archetype and express how uncertain it was about that suggestion.&lt;/p&gt;
&lt;p&gt;I know of two types of practitioners who face this problem. First are the companies that make collectible card games. They are often interested in assessing whether there is a sufficiently diverse array of successful archetypes, which requires efficiently classifying decks then calculating things like play- and win-rates by archetype. The developers can then either ban or change existing cards to improve the format. Second are third-party websites. They often provide “meta-game reports” that cover which archetypes are successful or likely to become successful. For them, the value of archetype statistics is simply to report them to players who have to decide which deck to bring to a tournament.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Data&lt;/h2&gt;
&lt;p&gt;The method I will describe relies on having a lot of decks with known archetypes. I will use data from &lt;a href=&#34;https://www.mtggoldfish.com/&#34;&gt;MTG Goldfish&lt;/a&gt; on Modern decks played in Star City Games (SCG) events from 2014 to the present. Modern is a non-rotating format, which means that cards from older sets will always be legal in the format. In a rotating format like Standard, where only cards from sets released in the past two years are legal, data on older decks is not useful to classify newer decks. Additionally, the names of deck archetypes at Star City Games events are more standardized than the weekly data from Magic Online (MTGO), the digital version of the game. The algorithm could be used in these other scenarios with enough data, but deck-lists are only released for top finishers at SCG events and on MTGO.&lt;/p&gt;
&lt;p&gt;Over the 841 tournaments, I observe 8,249 unique decks, 516 unique deck archetypes, and 1,772 unique cards. I will separate a 300 deck sample to use for testing after constructing the model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-method&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Method&lt;/h2&gt;
&lt;p&gt;I’ll start by defining some notation. &lt;span class=&#34;math inline&#34;&gt;\(D_{new}\)&lt;/span&gt; is a new deck that needs to be classified into an archetype. It is a list of card names and card quantities. It looks like this:&lt;/p&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
card
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
number
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Experiment One
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Goblin Guide
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Kird Ape
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wild Nacatl
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Burning-Tree Emissary
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Tarmogoyf
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We also have a set of training decks. The same card name and card quantity variables are included, but it also includes the true archetype name. The ultimate goal is to use the information in the training decks to classify a new deck of an unknown archetype.&lt;/p&gt;
&lt;div id=&#34;maximum-likelihood&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Maximum Likelihood&lt;/h3&gt;
&lt;p&gt;The simplest approach to the classification problem is to use a maximum likelihood estimation. In the training set, find the frequency that each card &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; appears among cards in archetype &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; and treat this as the probability that a random card from archetype &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; will be card &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;. For example, 1,653 Lightning Bolts appear among the 26,363 cards in Jund decks, so this probability would be estimated as 0.06. The likelihood that &lt;span class=&#34;math inline&#34;&gt;\(D_{new}\)&lt;/span&gt; came from archetype &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; can be thought of as the probability that 60 draws with replacement from a pool of every Magic card will result in &lt;span class=&#34;math inline&#34;&gt;\(D_{new}\)&lt;/span&gt; when the probability of drawing each card is given by the probabilities estimated for archetype &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; in the training data. Formally, this is a draw of size 60 from a Multinomial distribution on the population of every Magic card and probability parameters &lt;span class=&#34;math inline&#34;&gt;\(p_i = &amp;lt;p_{i,1},...,p_{i,1772}&amp;gt;\)&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(p_{i,c}\)&lt;/span&gt; is the proportion of card &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; among cards in archetype &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;. This is written below (note that &lt;span class=&#34;math inline&#34;&gt;\(x_c\)&lt;/span&gt; is the number of times card &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; appeared in &lt;span class=&#34;math inline&#34;&gt;\(D_{new}\)&lt;/span&gt;):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(D_{new}|\text{archetype}=i) = \frac{60!}{x_1! ... x_{1772}!} \prod_{c=i}^{1772}p_{c,i}^{x_c} \propto \prod_{c=i}^{1772}p_{c,i}^{x_c} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The most relevant part of this probability is the large product of each card frequency for each time it appears in &lt;span class=&#34;math inline&#34;&gt;\(D_{new}\)&lt;/span&gt;. The factorials just count the number of ways &lt;span class=&#34;math inline&#34;&gt;\(D_{new}\)&lt;/span&gt; could have been drawn. However, it can be completely ignored! We will classify &lt;span class=&#34;math inline&#34;&gt;\(D_{new}\)&lt;/span&gt; as whatever archetype maximizes the likelihood. The factorials are the same for every archetype, so ignoring them will not change the result.&lt;/p&gt;
&lt;p&gt;The biggest drawback of this method is that if a card is never observed in a given archetype in the training data, the estimated likelihood that any deck containing that card is of that archetype is zero. This can be particularly problematic. A blue-white control deck that decides to use Baneslayer Angel as a finisher might have 59 cards identical to a blue-white control deck in the training set, but it will have a likelihood of zero if no training blue-white control deck contained Baneslayer Angel.&lt;/p&gt;
&lt;p&gt;The solution to this problem is to add pseudo counts to every deck in the training set. Suppose you round every zero frequency to some small number, say 0.01. Now if a new card appears in an archetype, the likelihood will not be zero, and if the rest of the deck matches a known archetype well, it can still be correctly classified. Picking this pseudo count number can be hard. It should maybe even be different for different decks based on how many times that archetype is observed in the training set because you are likely more confident in zero frequencies for decks that you observe many times.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bayesian-modeling&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Bayesian Modeling&lt;/h3&gt;
&lt;p&gt;The method I propose is essentially a more rigorous way of adding these pseudo counts by putting a Bayesian prior on the frequencies. A useful distribution on a set of frequencies is the Dirichlet distribution. A draw from an n-dimensional Dirichlet distribution is a set of n positive numbers that sum to one. Note that n-1 dimensions identify the sample because the last dimension must ensure the values all sum to one. It has n parameters, call each &lt;span class=&#34;math inline&#34;&gt;\(\alpha_c\)&lt;/span&gt;, and the expected value for &lt;span class=&#34;math inline&#34;&gt;\(p_c\)&lt;/span&gt;, the frequency of card &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;, is &lt;span class=&#34;math inline&#34;&gt;\(\alpha_c/\sum_{j=1}^n \alpha_j\)&lt;/span&gt;. As &lt;span class=&#34;math inline&#34;&gt;\(\alpha_c\)&lt;/span&gt; increases, the variance decreases. To understand this distribution, its useful to first consider the two-dimensional case, called a &lt;a href=&#34;https://stephens999.github.io/fiveMinuteStats/beta.html&#34;&gt;Beta distribution&lt;/a&gt;. The link shows some useful visualizations of the distribution under different parameters. The Beta(1,1) distribution is uniform, Beta(5,5) has a peak at 0.5, Beta(1,4) has a peak at 0.25, Beta(0.1,0.1) has a minimum at 0.5 and has asymptotic behavior at 0 and 1.&lt;/p&gt;
&lt;p&gt;Suppose we start with a uniform Dirichlet prior for each deck (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_c = 1\)&lt;/span&gt; for all &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;), essentially starting from the position that all frequency combinations are equally likely. The intuition is that the model starts from the perspective that, without any data, the probability that a random draw of a single card from an archetype &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is a specific card &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is equal to &lt;span class=&#34;math inline&#34;&gt;\(1/n\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is the number of unique cards (1,772 in my data). The probability that a random card from an Infect deck is Lightning Bolt is 1/1,772, the probability that a random card from a Tron deck is Urza’s Mine is 1/1,772, etc. The uncertainty about these probabilities is also the same for every card in every archetype. Of course these probabilities are wrong in practice, but they provide a sensible starting point and will be updated with data.&lt;/p&gt;
&lt;p&gt;Next, we observe the training data for each archetype, &lt;span class=&#34;math inline&#34;&gt;\(D_t\)&lt;/span&gt;. Assuming that each archetype has a unique set of card frequencies, using proper Bayesian updating, the posterior distribution of frequencies (the distribution conditional on the data) for each archetype is also Dirichlet with parameters &lt;span class=&#34;math inline&#34;&gt;\(\alpha_c = 1 + n_c\)&lt;/span&gt;, the number of times card &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; appeared in the archetype across all decks in &lt;span class=&#34;math inline&#34;&gt;\(D_t\)&lt;/span&gt;. That is, starting from the prior stated above and given the training data, beliefs about the true card frequencies for each archetype are described by this distribution. To understand the intuition, after observing the training data, the probability that a single random card drawn from archetype &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is equal to a specific card &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is (1 + the number of card &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; that appeared in archetype &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; (&lt;span class=&#34;math inline&#34;&gt;\(n_{c,i}\)&lt;/span&gt;))/(&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; + the number of cards from archetype &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; (&lt;span class=&#34;math inline&#34;&gt;\(n_i\)&lt;/span&gt;)). For example, Lightning Bolt was never observed in an Infect deck, so the posterior expected probability that a random card from an Infect deck is Lightning Bolt is &lt;span class=&#34;math inline&#34;&gt;\((1+0)/(1,772+21,607) \approx 0.00013\)&lt;/span&gt;. Four copies of Urza’s Mine were observed in every Tron deck, so the posterior expected probability that a random card from a Tron deck is Urza’s Mine is &lt;span class=&#34;math inline&#34;&gt;\((1+1,272)/(1,772+19,099) \approx 0.061\)&lt;/span&gt;, which is pretty close to &lt;span class=&#34;math inline&#34;&gt;\(4/60 = 0.0\overline{6}\)&lt;/span&gt;. Using this method, an Infect deck splashing Lightning Bolt would not be ruled impossible, just extremely unlikely, and the model has determined that nearly every Tron deck has four Urza’s Mines. The posterior also captures differing levels of confidence in these estimations. The variance in frequencies for archetypes observed many times in &lt;span class=&#34;math inline&#34;&gt;\(D_t\)&lt;/span&gt; is lower than for archetypes observed fewer times because the variance decreases as the sum of the &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; parameters increases. In other words, I am more confident in the estimation of the frequency of Urza’s Mine in Tron, a heavily played deck, than I am about the frequency of Blood Moon in Skred Red decks, a rarely played deck.&lt;/p&gt;
&lt;p&gt;Finally, when encountering a new deck, we want to compute a posterior probability that the deck came from each of the archetypes we saw in the training data. Adopting a prior that without data each archetype is equally probable implies that the likelihood alone will determine this probability. A new deck, &lt;span class=&#34;math inline&#34;&gt;\(D_{new}\)&lt;/span&gt;, is a collection of 60 cards defined by a vector of &lt;span class=&#34;math inline&#34;&gt;\(x_c\)&lt;/span&gt;’s, the number of times card &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; appears in &lt;span class=&#34;math inline&#34;&gt;\(D_{new}\)&lt;/span&gt;. Our model interprets this deck as a draw of size 60 from a Multinomial-Dirichlet distribution on the set of all unique cards with Dirichlet parameters set by the posterior described above. This distribution is a Multinomial distribution where the frequency parameters are an unknown draw from a known Dirichlet distribution. So, for each archetype, the likelihood is computed as as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(\text{archetype} = i | D_{new},D_t,\alpha=1) \propto P(D_{new} | \text{archetype} = i,D_t,\alpha=1) = \]&lt;/span&gt; &lt;span class=&#34;math display&#34;&gt;\[f(D_{new};\text{size} = 60,\alpha_c = 1+n_{c,i}) = \frac{(60!) \Gamma(\sum_{c=1}^{1772} \alpha_c)}{\Gamma(60 + \sum_{c=1}^{1772} \alpha_c)} \prod_{c=1}^{1772} \frac{x_c + \alpha_c}{(x_c!) \Gamma(\alpha_c)} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt; is the pmf of the Multinomial-Dirichlet distribution and &lt;span class=&#34;math inline&#34;&gt;\(\Gamma\)&lt;/span&gt; is the gamma function, which is very similar to a factorial that can be applied non-integers. This function does look a lot more complicated than the simple likelihood before. That is because it is accounting for the uncertainty in the frequencies. You could simplify this function by using just the expectation of each frequency for each deck (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_c\)&lt;/span&gt; divided by the sum of the &lt;span class=&#34;math inline&#34;&gt;\(\alpha_c\)&lt;/span&gt;’s). That likelihood would look like the simple likelihood described previously where you can ignore the factorial constant and just take the product of each expected probability exponentiated by &lt;span class=&#34;math inline&#34;&gt;\(x_c\)&lt;/span&gt;. It would solve the problem of zero frequency cards. However, you would lose information about how confident you were in each expectation. The estimated frequencies of an archetype only observed twice in &lt;span class=&#34;math inline&#34;&gt;\(D_t\)&lt;/span&gt; should be viewed with more suspicion than the frequencies for one observed 500 times. That is the reason the gamma functions outside of the product cannot be ignored in this likelihood.&lt;/p&gt;
&lt;p&gt;After computing each of these, standardize them to sum to one and you have the probability that the new deck came from each of the observed archetypes. Classify it into whichever archetype has the highest probability and you’re done!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;results&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Results&lt;/h2&gt;
&lt;p&gt;Available on &lt;a href=&#34;https://github.com/g-tierney/magic_deck_classification_multi_dir&#34;&gt;Github is R code&lt;/a&gt; that implements the above method, allowing for a flexible specification of &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; in the prior. I chose &lt;span class=&#34;math inline&#34;&gt;\(\alpha=1\)&lt;/span&gt; because it represents starting from a uniform distribution, but the choice of prior is certainly open for debate. I also show the results for &lt;span class=&#34;math inline&#34;&gt;\(\alpha=0\)&lt;/span&gt;, which corresponds to the initial maximum likelihood setup where zero frequencies are possible.&lt;/p&gt;
&lt;p&gt;The results for &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; equal to 0, 1, and 0.01 are reported below. &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; of 0.01 corresponds to a prior with a smaller effect on the posterior (each &lt;span class=&#34;math inline&#34;&gt;\(\alpha_c\)&lt;/span&gt; will be &lt;span class=&#34;math inline&#34;&gt;\(0.01 + n_{c,i}\)&lt;/span&gt;) and frequencies closer to zero are more likely. Correct is the number of correct classifications, Size is the number of decks classified, and Rate is the ratio of those two. The Confident columns subset the results to classifications were the posterior probability of the suggested classification is greater than 95%.&lt;/p&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Alpha
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Correct
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Size
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Rate
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Correct (Confident)
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Size (Confident)
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Rate (Confident)
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
300
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
NaN
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.01
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
235
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
300
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.78
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
224
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
278
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.81
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.00
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
239
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
300
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.80
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
236
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
292
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.81
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The value of &lt;span class=&#34;math inline&#34;&gt;\(\alpha=1\)&lt;/span&gt; appears to be the most accurate, getting 80% of classifications correct, but the smaller &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; is not very different. It is also worth noting that the method appears to be too confident in its classifications. One would hope the accuracy rate would be similar to the estimated probability, but it appears that the classifications made with at least 95% probability have an accuracy rate well below that number.&lt;/p&gt;
&lt;p&gt;I will look at the accuracy rate by archetype as well. The table below shows the five most frequent and five least frequent archetypes observed in the testing data. Total is the number of times the archetype appears, Proportion Correct is the proportion of those decks that are correctly classified, and Mode Incorrect is the most common incorrect classification (missing values indicate that all decks are correctly classified).&lt;/p&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Deck
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Total
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Proportion Correct
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Mode Incorrect
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Infect
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
19
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Jund
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
17
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Naya Burn
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.93
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Burn
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Tron
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Affinity
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
14
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wr
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wr Prison
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wr Control
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wr Prison
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wr Prison
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Rw Nahiri
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wrg
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Naya Zoo
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wu Control
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Uw Control
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Infect, Tron, and Affinity are very unique decks, so it is not surprising that the algorithm correctly classifies them. Jund is very similar to many other black green midrange decks, so I was surprised they were all correctly identified. That could be because Jund is a very common archetype in the training decks, so the algorithm has enough data to separate Jund from similar decks. Naya Burn was most frequently miss classified as normal Burn, which is not very surprising.&lt;/p&gt;
&lt;p&gt;Among the least frequent archetypes, the mistakes are not unexpected. Its possible that WR, WR Control, and WR Prison should be the same archetype anyway, and the difference between WU Control versus UW Control is just which color is more prevalent.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;human-improvements&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Human Improvements&lt;/h2&gt;
&lt;p&gt;I think a lot of the time, people want their statistical model to work without any human input. However, human-level tweaks often provide significantly greater performance improvements than tweaks to the statistical methods. Three areas where an analyst with domain knowledge could improve the method are outlined below.&lt;/p&gt;
&lt;p&gt;First, standardizing deck archetypes. I made a few changes to these but wanted to leave the data mostly raw. For example, I made “U/R Twin” and “UR Twin” the same deck, changed “Death &amp;amp; Taxes” to “Death And Taxes”, and standardized capitalization. Several remaining archetypes, however, should probably be grouped together. Some low hanging fruit are probably the 38 “Naya Through the Breach” decks and the 21 “Naya Titan Breach” decks, and the 88 “UB Tezzerator” and 26 “UB Tezzeret” decks. These kind of changes could be made incrementally as more data are added by standardizing the names of new decks and by someone who was unfamiliar with the code and statistics, but was familiar with the Modern format.&lt;/p&gt;
&lt;p&gt;Another area an analyst could improve these results is by selectively including true zeros in the likelihood. For example, Abzan compared to Abzan Company decks differ by whether the card Collected Company is included in the list. With enough data, the algorithm will learn this distinction, but that identification could be expedited and accuracy increased if the Abzan likelihood function had a zero frequency for Collected Company. A similar method could be used to separate similar archetypes defined by color splashes, such as distinguishing Jeskai Twin, Grixis Twin, and UR Twin by including zeros for lands by which color they produce.&lt;/p&gt;
&lt;p&gt;A third and final area more domain knowledge could help is manually reviewing low probability classifications. Let’s look at the most uncertain classifications. These six decks are the ones the algorithm had the most uncertainty about. An analyst could review these decks to separate archetypes that are quite similar.&lt;/p&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Deck
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Classification
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Probability Correct
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Correct
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Burn
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Burn
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.59
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
TRUE
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mono-Blue Grand Architect
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mono-Blue Turns
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.74
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
FALSE
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Tasigur Burn
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Unknown
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.77
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
FALSE
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mono-Blue Grand Architect
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mono-Blue Turns
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.84
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
FALSE
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mono-White Human Aggro
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mono-White Humans
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.85
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
FALSE
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Wr Prison
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Rw Nahiri
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.90
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
FALSE
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;implementation-in-practice&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Implementation in Practice&lt;/h2&gt;
&lt;p&gt;A company or data scientist building this tool for frequent use in an analysis pipeline would want to design a few features beyond the one-time estimation and classification described here.&lt;/p&gt;
&lt;p&gt;Training data updating. CCGs evolve over time with new card releases and novel combinations discovered by players. When a new archetype is formed, examples of it need to be added to the training data. To that end, and to update old archetypes with new cards, samples of decks should be regularly classified by humans and added to the training data, with special emphasis placed on getting sufficient samples of new archetypes. It would also be wise to sample more heavily from decks with low probability classifications and track accuracy rates of the new training decks.&lt;/p&gt;
&lt;p&gt;Archetype hierarchies. Many of the incorrect classifications were from mistaking sub-archetypes, such as confusing Naya Burn for Burn or Wilt-Leaf Abzan for Abzan. A two-stage classification could be more accurate and better address the questions practitioners are asking. An analyst would place some archetypes into categories, all Burn decks into one category and all Abzan into another. The algorithm would be implemented twice. Once to place a deck into a category then again to place the deck within that category. The higher-level category will probably be more accurate and sufficient for most practitioners’ purposes.&lt;/p&gt;
&lt;p&gt;Prior selection. The uniform prior of &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 1\)&lt;/span&gt; is useful for interpretation, but practitioners may find it to be less accurate for archetypes with small sample sizes. Selecting the &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; that maximizes the accuracy rate in the training data is one simple option, or a cross-validation method could pick &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; to maximize the accuracy rate across many samples.&lt;/p&gt;
&lt;p&gt;Incorporating game-specific features. Every CCG has unique deck-building rules, which could be built into the likelihood function. Magic decks cannot contain more than four of a single card and no fewer than 60 total cards, so frequencies greater than 4/60 are impossible. In Hearthstone, the cap is two for some cards, one for others, and decks must be exactly 30 cards. Deck size is already included as a parameter in the Multinomial-Dirichlet distribution, but card limits are not. Two alternatives I tried were treating each deck as a series of Bernoulli random variables indicating whether a card was present or not in a deck and treating a deck as a draw from several Multinomial distributions of size 4 (or the appropriate card limit). They were not as accurate as the method described here, but potentially could be improved. At the least, they are worth experimenting with on new data sets.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;machine-learning-methods&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Machine Learning Methods&lt;/h2&gt;
&lt;p&gt;I am certain that there are machine learning methods that address this problem as well. Classification is a well-studied topic in machine learning and this classification problem does not present too many unique challenges. However, I think this Bayesian approach has certain advantages in model updating and uncertainty quantification. It is quite easy to update the model with new, correctly-labeled decks. Simply add the new card counts the appropriate archetype in the training data. Many ML methods would need to re-calibrate tuning and regularization parameters with new training data, which could be quite time consuming. The second advantage is uncertainty quantification. Given the prior, this model explicitly reports the probability that the classification is correct. This is useful in flagging cases for manual review, as noted above.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;While not perfect, this algorithm should become quite adept at identifying archetypes with enough data. In formats without much turnover in the top decks, collecting the amount of data required is not very difficult. In rotating formats, however, it could be much harder. The people interested in this kind of application, however, might have more than just the top decks from weekend tournaments. Wizards of the Coast, the company that makes Magic, can observe every game played on Magic Online, tournament organizers collect deck lists from every player, and Vicious Syndicate has a popular deck tracking app for Hearthstone. They can certainly collect enough samples of decks, and perhaps the method described here could improve their classification accuracy or reduce the human labor required.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
